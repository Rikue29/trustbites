"""
Live Restaurant Scraping: Bukit Bintang, Kuala Lumpur
======================================================
Real-time scraping of restaurants and reviews from a popular KL area
"""

import requests
import json
from datetime import datetime
import time

GOOGLE_API_KEY = "AIzaSyB_cVKxLR2idCaCFLdDavry-pDF6BhNgiQ"
PLACES_API_BASE = "https://maps.googleapis.com/maps/api/place"

def live_scrape_bukit_bintang():
    """Live scrape restaurants in Bukit Bintang area with real reviews"""
    
    print("ğŸ”´ LIVE: Scraping Bukit Bintang, Kuala Lumpur")
    print("=" * 50)
    print(f"â° Started at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    # Search for restaurants in Bukit Bintang
    search_location = "Bukit Bintang, Kuala Lumpur, Malaysia"
    
    print(f"ğŸ¯ Target Area: {search_location}")
    print("ğŸ” Searching for restaurants...")
    
    # Use Nearby Search for area-based results
    nearby_url = f"{PLACES_API_BASE}/nearbysearch/json"
    
    # Get coordinates for Bukit Bintang first
    geocode_url = "https://maps.googleapis.com/maps/api/geocode/json"
    geocode_params = {
        'address': search_location,
        'key': GOOGLE_API_KEY
    }
    
    geocode_response = requests.get(geocode_url, params=geocode_params)
    geocode_data = geocode_response.json()
    
    if geocode_data['status'] != 'OK':
        print("âŒ Failed to get location coordinates")
        return
    
    location = geocode_data['results'][0]['geometry']['location']
    print(f"ğŸ“ Coordinates: {location['lat']}, {location['lng']}")
    
    # Search for restaurants nearby
    search_params = {
        'location': f"{location['lat']},{location['lng']}",
        'radius': 1000,  # 1km radius
        'type': 'restaurant',
        'key': GOOGLE_API_KEY
    }
    
    print("\nğŸ”„ Fetching restaurants...")
    response = requests.get(nearby_url, params=search_params)
    
    if response.status_code != 200:
        print(f"âŒ API Error: {response.status_code}")
        return
    
    data = response.json()
    
    if data['status'] != 'OK':
        print(f"âŒ Search failed: {data['status']}")
        return
    
    restaurants = data['results']
    print(f"âœ… Found {len(restaurants)} restaurants in Bukit Bintang area")
    print()
    
    # Select top 5 restaurants for detailed scraping
    top_restaurants = sorted(restaurants, key=lambda x: x.get('rating', 0), reverse=True)[:5]
    
    scraped_data = []
    
    for i, restaurant in enumerate(top_restaurants, 1):
        print(f"ğŸª Restaurant {i}/5: {restaurant['name']}")
        print("-" * 40)
        print(f"â­ Rating: {restaurant.get('rating', 'N/A')}")
        print(f"ğŸ’° Price Level: {restaurant.get('price_level', 'N/A')}")
        print(f"ğŸ‘¥ Total Ratings: {restaurant.get('user_ratings_total', 'N/A')}")
        
        # Get detailed information with reviews
        print("ğŸ“„ Fetching detailed reviews...")
        
        details_url = f"{PLACES_API_BASE}/details/json"
        details_params = {
            'place_id': restaurant['place_id'],
            'key': GOOGLE_API_KEY,
            'fields': 'name,formatted_address,rating,user_ratings_total,reviews,opening_hours,formatted_phone_number,website,photos'
        }
        
        details_response = requests.get(details_url, params=details_params)
        
        if details_response.status_code == 200:
            details_data = details_response.json()
            
            if details_data['status'] == 'OK':
                restaurant_details = details_data['result']
                reviews = restaurant_details.get('reviews', [])
                
                print(f"âœ… Retrieved {len(reviews)} live reviews")
                
                # Show real reviews
                if reviews:
                    print("\nğŸ“ LIVE REVIEWS:")
                    print("=" * 30)
                    
                    for j, review in enumerate(reviews[:3], 1):  # Show first 3 reviews
                        print(f"\nğŸ’¬ Review {j}:")
                        print(f"   ğŸ‘¤ {review['author_name']}")
                        print(f"   â­ {review['rating']}/5 stars")
                        print(f"   ğŸ“… {review['relative_time_description']}")
                        print(f"   ğŸ“ \"{review['text'][:150]}{'...' if len(review['text']) > 150 else ''}\"")
                        
                        # Language detection
                        if 'language' in review:
                            print(f"   ğŸŒ Language: {review['language']}")
                
                # Store scraped data
                restaurant_data = {
                    "scrapedAt": datetime.now().isoformat(),
                    "placeId": restaurant['place_id'],
                    "name": restaurant_details['name'],
                    "address": restaurant_details.get('formatted_address', ''),
                    "rating": restaurant_details.get('rating'),
                    "totalReviews": restaurant_details.get('user_ratings_total'),
                    "phone": restaurant_details.get('formatted_phone_number'),
                    "website": restaurant_details.get('website'),
                    "area": "Bukit Bintang, Kuala Lumpur",
                    "liveReviews": [
                        {
                            "author": review['author_name'],
                            "rating": review['rating'],
                            "text": review['text'],
                            "time": review['relative_time_description'],
                            "language": review.get('language', 'unknown')
                        } for review in reviews[:5]  # Store first 5 reviews
                    ]
                }
                
                scraped_data.append(restaurant_data)
                
            else:
                print(f"âŒ Failed to get details: {details_data['status']}")
        else:
            print(f"âŒ HTTP Error: {details_response.status_code}")
        
        print()
        # Small delay to be respectful to API
        time.sleep(1)
    
    # Summary of live scraping results
    print("ğŸ¯ LIVE SCRAPING SUMMARY")
    print("=" * 30)
    print(f"ğŸ“ Area: Bukit Bintang, Kuala Lumpur")
    print(f"ğŸª Restaurants scraped: {len(scraped_data)}")
    print(f"â° Completed at: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
    print()
    
    total_reviews = sum(len(r['liveReviews']) for r in scraped_data)
    print(f"ğŸ“Š Total live reviews collected: {total_reviews}")
    print(f"â­ Average rating of scraped restaurants: {sum(r['rating'] or 0 for r in scraped_data) / len(scraped_data):.1f}")
    print()
    
    # Show detailed results
    print("ğŸ“‹ DETAILED SCRAPING RESULTS:")
    print("=" * 35)
    
    for i, restaurant in enumerate(scraped_data, 1):
        print(f"\nğŸª {i}. {restaurant['name']}")
        print(f"   ğŸ“ {restaurant['address']}")
        print(f"   â­ {restaurant['rating']} ({restaurant['totalReviews']} total reviews)")
        print(f"   ğŸ“ {restaurant['phone'] or 'N/A'}")
        print(f"   ğŸŒ {restaurant['website'] or 'N/A'}")
        print(f"   ğŸ’¬ Live reviews collected: {len(restaurant['liveReviews'])}")
        
        # Show one sample review per restaurant
        if restaurant['liveReviews']:
            sample_review = restaurant['liveReviews'][0]
            print(f"   ğŸ“ Sample review: \"{sample_review['text'][:100]}...\" - {sample_review['author']} ({sample_review['rating']}â­)")
    
    # Save to JSON file for further analysis
    output_file = f"bukit_bintang_live_scrape_{datetime.now().strftime('%Y%m%d_%H%M%S')}.json"
    
    with open(output_file, 'w', encoding='utf-8') as f:
        json.dump({
            "scrapeInfo": {
                "area": "Bukit Bintang, Kuala Lumpur, Malaysia",
                "timestamp": datetime.now().isoformat(),
                "totalRestaurants": len(scraped_data),
                "totalReviews": total_reviews
            },
            "restaurants": scraped_data
        }, f, indent=2, ensure_ascii=False)
    
    print(f"\nğŸ’¾ Data saved to: {output_file}")
    print("ğŸš€ Live scraping completed successfully!")
    print()
    print("ğŸ¤– This data is now ready for:")
    print("   â€¢ AI fake review detection")
    print("   â€¢ Sentiment analysis")
    print("   â€¢ Restaurant recommendation algorithms")
    print("   â€¢ Market trend analysis")
    print("   â€¢ Consumer trust scoring")

if __name__ == "__main__":
    live_scrape_bukit_bintang()